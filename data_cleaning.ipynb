{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevent libraries\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into dataframe\n",
    "\n",
    "file = \"allegations_202007271729.csv\"\n",
    "\n",
    "complaints_df = pd.read_csv(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for EDA, cleaning and for later QA\n",
    "\n",
    "def get_info(dataframe):\n",
    "    return dataframe.info()\n",
    "\n",
    "def data_shape(dataframe):\n",
    "    if dataframe.shape() != (0,0):\n",
    "        return dataframe.shape()\n",
    "    else:\n",
    "        return \"There is an error with your dataframe\"\n",
    "    \n",
    "def dataframe_preview(dataframe):\n",
    "    return dataframe.head()\n",
    "\n",
    "def describe_df(dataframe):\n",
    "    return dataframe.describe()\n",
    "\n",
    "def unique_counts(dataframe):\n",
    "    return dataframe.apply(pd.Series.value_counts)\n",
    "\n",
    "def dataframe_correlation(dataframe):\n",
    "    return dataframe.corr()\n",
    "\n",
    "def check_dups(dataframe):\n",
    "    duplicates = dataframe[dataframe.duplicated()]\n",
    "    num_dups = len(duplicates)\n",
    "    if num_dups > 0:\n",
    "        return f\"There are {num_dups} duplicates in your dataset\", duplicates\n",
    "    else:\n",
    "        return f\"There are {num_dups} duplicates in your dataset\"\n",
    "\n",
    "def check_nulls(dataframe):\n",
    "    num_nulls = dataframe.isnull().sum()\n",
    "    return num_nulls\n",
    "\n",
    "def drop_dups(dataframe):\n",
    "    dataframe = dataframe.drop_duplicates()\n",
    "    return dataframe\n",
    "\n",
    "def drop_nulls(dataframe):\n",
    "    dataframe = dataframe.dropna()\n",
    "    return dataframe\n",
    "\n",
    "def change_data_type(dataframe, column_names, data_type):\n",
    "    dataframe[column_names].astype(data_type)\n",
    "    return dataframe\n",
    "\n",
    "#function to combine month and year\n",
    "def make_complaint_date(dataframe, year_column, month_column):\n",
    "    dataframe['complaint_date'] = pd.to_datetime(dataframe[year_column].astype(str) + '-' + dataframe[month_column].astype(str) + '-01')\n",
    "    return dataframe\n",
    "\n",
    "def make_resolved_date(dataframe, year_column, month_column):\n",
    "    dataframe['resolved_date'] = pd.to_datetime(dataframe[year_column].astype(str) + '-' + dataframe[month_column].astype(str) + '-01')\n",
    "    return dataframe\n",
    "    \n",
    "#Change M and F to Male and Female respectively\n",
    "def longform_sex(dataframe, gender_column):\n",
    "    dataframe[gender_column] = dataframe[gender_column].replace('M', 'Male').replace('F', 'Female')\n",
    "    return dataframe\n",
    "\n",
    "#create dictionaries\n",
    "def create_dictionary(dataframe, first_column, second_column):\n",
    "   new_dict = dict(zip(dataframe[first_column], dataframe[second_column]))\n",
    "   return new_dict\n",
    "\n",
    "#replace abbreviations\n",
    "def replace_abbreviations(dataframe, dict_name):\n",
    "    return dataframe.replace(dict_name)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA Findings:\n",
    "27 columns with 33,357 rows\n",
    "Appears to be missing data in some rows\n",
    "Dates need to be made, currently separate columns for month and day\n",
    "unique_mos_id, shield_no, complaint_id, precinct are ints and would be better in string format\n",
    "1985 to 1998 had a null rate of 92% or higher for complainant age, gender, and ethnicity\n",
    "only 4 rows for the year 2020\n",
    "noticed discrepancy between gender classification for police and complainants - changed to full form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_info(complaints_df)\n",
    "#code below is to see \"missing\" columns\n",
    "#get_info(complaints_df.iloc[:,20:27])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get preview of columns, abbreviations for commands and ranks need to be converted to full form\n",
    "dataframe_preview(complaints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_mod_id, shield_no, complaint_id, precinct are all ints and would be better as strings, same with year and month columns\n",
    "#complainant age has a min age of -4301, further analysis will be required\n",
    "#lots of missing values in complainant age\n",
    "describe_df(complaints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check duplicates\n",
    "#631 duplicates in the data\n",
    "check_dups(complaints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check nulls\n",
    "#lots of nulls in command at incident, complainant ethnicity, age, and gender these are the important ones\n",
    "check_nulls(complaints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check rate of nulls by year for complainant ethnicity, age, and gender\n",
    "#check nulls by year\n",
    "by_year = complaints_df.groupby('year_received')\n",
    "null_counts = by_year[['complainant_age_incident', 'complainant_ethnicity', 'complainant_gender']].apply(lambda x: x.isnull().sum())\n",
    "#null_counts\n",
    "\n",
    "null_counts['total rows'] = by_year['unique_mos_id'].count()\n",
    "\n",
    "null_counts['percent of total age'] = null_counts['complainant_age_incident']/null_counts['total rows']\n",
    "null_counts['percent of total ethnicity'] = null_counts['complainant_ethnicity']/null_counts['total rows']\n",
    "null_counts['percent of total gender'] = null_counts['complainant_gender']/null_counts['total rows']\n",
    "null_percentages = null_counts[['percent of total age', 'percent of total ethnicity', 'percent of total gender', 'total rows']]\n",
    "null_percentages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of rows by age. \n",
    "#Remove ages 9 and under as rows limited.\n",
    "count_age = complaints_df.groupby('complainant_age_incident').count()\n",
    "count_age.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "semi_clean_df = drop_dups(complaints_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load abbreviation file and get sheet names\n",
    "abbreviation_file = 'CCRB Data Layout Table.xlsx'\n",
    "data_df = pd.ExcelFile(abbreviation_file)\n",
    "data_df.sheet_names\n",
    "\n",
    "# read sheets\n",
    "rank_abbv = pd.read_excel(data_df, 'Rank Abbrevs')\n",
    "command_abbv = pd.read_excel(data_df, 'Command Abbrevs')\n",
    "\n",
    "# make dictionaries\n",
    "ranks = create_dictionary(rank_abbv, 'Abbreviation', 'Rank')\n",
    "commands = create_dictionary(command_abbv, 'Abbreviation', 'Command Name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter age group\n",
    "semi_clean_df = semi_clean_df[semi_clean_df['complainant_age_incident'] >= 10]\n",
    "\n",
    "#replace abbreviations\n",
    "semi_clean_df = replace_abbreviations(semi_clean_df, ranks)\n",
    "semi_clean_df = replace_abbreviations(semi_clean_df, commands)\n",
    "\n",
    "#make dates\n",
    "semi_clean_df = make_complaint_date(semi_clean_df, 'year_received', 'month_received')\n",
    "semi_clean_df = make_resolved_date(semi_clean_df, 'year_closed', 'month_closed')\n",
    "\n",
    "#standardize genders\n",
    "semi_clean_df = longform_sex(semi_clean_df, 'mos_gender')\n",
    "\n",
    "#change data types\n",
    "semi_clean_df = change_data_type(semi_clean_df, column_names=['unique_mos_id', 'shield_no', 'complaint_id', 'precinct'], data_type=str)\n",
    "\n",
    "\n",
    "#Drop null for semi_clean_data for inital Tableau experiments\n",
    "semi_clean_drop_null = drop_nulls(semi_clean_df)\n",
    "\n",
    "#replace nulls with \"no record\"\n",
    "Final_df = semi_clean_df.fillna(\"No Records Available\")\n",
    "\n",
    "#Filter years in final_df\n",
    "Final_df = Final_df[(Final_df['year_received'] >= 1999) & (Final_df['year_received'] < 2020)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save final_df as csv\n",
    "Final_df.to_csv('final_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save semi clean data as csv\n",
    "semi_clean_drop_null.to_csv('semi_clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure out what to do with nulls\n",
    "#command at incidence 1544 - maybe do count of values in non-null, count $of total then assign at random for nulls\n",
    "#complainant race, gener, age have most nulls and crucial data\n",
    "#allegation has 1\n",
    "#precent has 24\n",
    "#contact_reason 199\n",
    "#outcome description 56"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so for nulls, put them all as \"no record\" then on dashboard have a filter drop 2020 because only 4 rows, use 1999 to 2019, because 1985 to 98 had 99% null rate talk about history of ccrb from their website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so for nulls, put them all as \"no record\" then on dashboard have a filter drop 2020 because only 4 rows, use 1999 to 2019, because 1985 to 98 had 99% null rate talk about history of ccrb from their website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
